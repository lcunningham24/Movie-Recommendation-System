{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 4 Final Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2: Recommendation System\n",
    "\n",
    "If you choose the Recommendation System option, you will be making movie recommendations based on the MovieLens dataset from the GroupLens research lab at the University of Minnesota. Unless you are planning to run your analysis on a paid cloud platform, we recommend that you use the \"small\" dataset containing 100,000 user ratings (and potentially, only a particular subset of that dataset).\n",
    "\n",
    "**Your task is to:**\n",
    "\n",
    "Build a model that provides top 5 movie recommendations to a user, based on their ratings of other movies.\n",
    "\n",
    "The MovieLens dataset is a \"classic\" recommendation system dataset, that is used in numerous academic papers and machine learning proofs-of-concept. You will need to create the specific details about how the user will provide their ratings of other movies, in addition to formulating a more specific business problem within the general context of \"recommending movies\".\n",
    "\n",
    "**Collaborative Filtering**\n",
    "\n",
    "At minimum, your recommendation system must use collaborative filtering. If you have time, consider implementing a hybrid approach, e.g. using collaborative filtering as the primary mechanism, but using content-based filtering to address the cold start problem.\n",
    "\n",
    "**Evaluation**\n",
    "\n",
    "The MovieLens dataset has explicit ratings, so achieving some sort of evaluation of your model is simple enough. But you should give some thought to the question of metrics. Since the rankings are ordinal, we know we can treat this like a regression problem. But when it comes to regression metrics there are several choices: RMSE, MAE, etc. Here are some further ideas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movie Recommendation System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading csv's into dataframes\n",
    "ratings = pd.read_csv('ratings.csv')\n",
    "tags = pd.read_csv('tags.csv')\n",
    "movies = pd.read_csv('movies.csv')\n",
    "links = pd.read_csv('links.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Content of Files\n",
    "\n",
    "**ratings:** \n",
    "- Each row represents one rating of one movie by one user\n",
    "- Ratings are made on a 5-star scale, with half-star increments \n",
    "\n",
    "**tags:** \n",
    "- Each row represents one tag applied to one movie by one user\n",
    "- Tags are user-generated metadata about movies. Each tag is typically a single word or short phrase. The meaning, value, and purpose of a particular tag is determined by each user\n",
    "\n",
    "**movies:** \n",
    "- Each row represents one movie\n",
    "- Movie titles are entered manually or imported from https://www.themoviedb.org/, and include the year of release in parentheses. Errors and inconsistencies may exist in these titles\n",
    "\n",
    "**links:** \n",
    "- Identifiers that can be used to link to other sources of movie data; each row represents one movie\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964981247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964983815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964982931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating  timestamp\n",
       "0       1        1     4.0  964982703\n",
       "1       1        3     4.0  964981247\n",
       "2       1        6     4.0  964982224\n",
       "3       1       47     5.0  964983815\n",
       "4       1       50     5.0  964982931"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tags.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "links.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# merging movie and rating dataframes \n",
    "df = ratings.merge(movies,on='movieId', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# dropping timestamp column\n",
    "df.drop(columns = 'timestamp',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating year column\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### genre categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating dictionary of genres \n",
    "genres = []\n",
    "for row in df['genres']: \n",
    "    genres.extend(row.split('|'))\n",
    "genre_dict = {}\n",
    "for genre in genres:\n",
    "    if genre in genre_dict: \n",
    "        genre_dict[genre] += 1\n",
    "    else:\n",
    "        genre_dict[genre] = 1\n",
    "# creating df \n",
    "genres = {'Genre': list(genre_dict.keys()), 'Count': list(genre_dict.values())}\n",
    "genre_df = pd.DataFrame(genres)\n",
    "sorted_genres = genre_df.sort_values(by='Count',ascending=False)\n",
    "sorted_genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# barplot of genres\n",
    "x = sorted_genres['Genre']\n",
    "y = sorted_genres['Count']\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20,10))\n",
    "ax.bar(x,y)\n",
    "sns.barplot(x,y)\n",
    "\n",
    "ax.set_xticklabels(x,rotation=80)\n",
    "ax.set_ylabel(\"Count of Genre\")\n",
    "ax.set_title(\"Count of Genres in Dataset\");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = df['rating'].value_counts().sort_index(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax = ratings.plot(kind=\"bar\")\n",
    "ax.set_ylabel('Count')\n",
    "ax.set_xlabel('Ratings')\n",
    "ax.set_title('Frequency of Ratings by Users');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collaborative Filtering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!Pip install scikit-surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping timestamp column and converting ratings file to a df\n",
    "ratings = ratings.drop(columns='timestamp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading in the ratings dataset using surprise\n",
    "from surprise import Reader, Dataset\n",
    "from surprise.model_selection import train_test_split\n",
    "reader = Reader()\n",
    "data = Dataset.load_from_df(ratings, reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users:  610 \n",
      "\n",
      "Number of items:  9724\n"
     ]
    }
   ],
   "source": [
    "# checking how many users and items in our dataset \n",
    "dataset = data.build_full_trainset()\n",
    "print('Number of users: ', dataset.n_users, '\\n')\n",
    "print('Number of items: ', dataset.n_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries for modeling\n",
    "from surprise.model_selection import cross_validate\n",
    "from surprise.prediction_algorithms import SVD\n",
    "from surprise.prediction_algorithms import KNNWithMeans, KNNBasic, KNNBaseline\n",
    "from surprise.model_selection import GridSearchCV\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# performing gridsearch with SVD\n",
    "params = {'n_factors': [20, 50, 100],\n",
    "         'reg_all': [0.02, 0.05, 0.1]}\n",
    "g_s_svd = GridSearchCV(SVD,param_grid=params,n_jobs=-1)\n",
    "g_s_svd.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rmse': 0.868711086651938, 'mae': 0.6675606029080111}\n",
      "{'rmse': {'n_factors': 100, 'reg_all': 0.05}, 'mae': {'n_factors': 100, 'reg_all': 0.05}}\n"
     ]
    }
   ],
   "source": [
    "# determining best score and params\n",
    "print(g_s_svd.best_score)\n",
    "print(g_s_svd.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross validating with KNN basic \n",
    "knn_basic = KNNBasic(sim_options={'name':'pearson', 'user_based':True})\n",
    "cv_knn_basic = cross_validate(knn_basic, data, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('test_rmse', array([0.97361981, 0.96966963, 0.97440021, 0.9823685 , 0.96740846]))\n",
      "('test_mae', array([0.75218065, 0.7478337 , 0.75167886, 0.75956303, 0.746431  ]))\n",
      "('fit_time', (0.351093053817749, 0.3658719062805176, 0.3702709674835205, 0.36009883880615234, 0.3330380916595459))\n",
      "('test_time', (1.1610181331634521, 1.1606900691986084, 1.2329440116882324, 1.1385619640350342, 1.1787469387054443))\n",
      "-----------------------\n",
      "0.9734933220784328\n"
     ]
    }
   ],
   "source": [
    "for i in cv_knn_basic.items():\n",
    "    print(i)\n",
    "print('-----------------------')\n",
    "print(np.mean(cv_knn_basic['test_rmse']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    }
   ],
   "source": [
    "# cross validating with KNN baseline \n",
    "knn_baseline = KNNBaseline(sim_options={'name':'pearson', 'user_based':True})\n",
    "cv_knn_baseline = cross_validate(knn_baseline,data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('test_rmse', array([0.87824802, 0.88788667, 0.8770327 , 0.87187538, 0.87506507]))\n",
      "('test_mae', array([0.67235431, 0.67386793, 0.67114579, 0.66666312, 0.66795117]))\n",
      "('fit_time', (0.7323458194732666, 0.6480069160461426, 0.6585133075714111, 0.6702239513397217, 0.6465158462524414))\n",
      "('test_time', (1.6693470478057861, 1.729867935180664, 1.8060507774353027, 1.7526829242706299, 1.7236599922180176))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8780215682451843"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in cv_knn_baseline.items():\n",
    "    print(i)\n",
    "\n",
    "np.mean(cv_knn_baseline['test_rmse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Content-Based Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
